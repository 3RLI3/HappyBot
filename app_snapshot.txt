📁 APP STRUCTURE

app/
  sea_lion_api.py
  utils.py
  session_db.py
  telegram_bot.py
  __init__.py
  langchain_prompts.py

📄 FILE CONTENTS

--- sea_lion_api.py ---
import os
import requests
import logging
from dotenv import load_dotenv
from app.langchain_prompts import format_prompt
from app.session_db import append_user_history

load_dotenv()

API_KEY = os.getenv("SEA_LION_API_KEY")
BASE_URL = "https://api.sea-lion.ai/v1/chat/completions"
MODEL_NAME = "aisingapore/Gemma-SEA-LION-v3-9B-IT"

HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

def generate_response(query: str, context: str = "general_conversation", user_id: int = None) -> str:
    """
    Generate a model response using Sea-Lion API with optional memory and context.

    Args:
        query (str): The user's input.
        context (str): Context label for prompt formatting.
        user_id (int, optional): User ID to retrieve conversation history.

    Returns:
        str: The LLM-generated response.
    """
    prompt = format_prompt(context, query, user_id=user_id)

    payload = {
        "model": MODEL_NAME,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7
    }

    try:
        response = requests.post(BASE_URL, headers=HEADERS, json=payload, timeout=10)
        response.raise_for_status()
        result = response.json()

        reply = result["choices"][0]["message"]["content"].strip()
        if user_id:
            append_user_history(user_id, query, reply)

        return reply

    except requests.RequestException as e:
        logging.exception("Sea-Lion API request failed")
        return "⚠️ Sorry, I'm having trouble connecting to the assistant. Please try again shortly."
    except (KeyError, IndexError):
        logging.exception("Unexpected response format from Sea-Lion API")
        return "⚠️ I didn't understand that. Can you try rephrasing?"

--- utils.py ---
# Intent Classification (Context Detection) - Simple Keyword-based Classifier to determine the conversational category from user input
import re
import logging

# Enhanced keyword mapping
CONTEXT_KEYWORDS = {
    "daily_life": ["cook", "cooking", "grocery", "medicine", "shopping", "weather", "laundry", "clean", "meal"],
    "health_wellness": ["exercise", "headache", "sleep", "wellness", "pain", "diet", "walk", "health", "hydrate"],
    "emotional_support": ["lonely", "sad", "depressed", "friends", "family", "anxious", "worried", "bored", "stressed"],
    "technology_help": ["phone", "video call", "zoom", "whatsapp", "alarm", "scam", "wifi", "reset", "slow", "computer", "tablet"],
    "local_culture": ["events", "places", "heritage", "museum", "history", "tv show", "drama", "hawker", "festival"],
}

def detect_context(user_input: str) -> str:
    """
    Determine conversational context from user input using keyword matching.
    Falls back to 'general_conversation' if no match is found.
    """
    ui = user_input.lower()
    for context, keywords in CONTEXT_KEYWORDS.items():
        for word in keywords:
            if re.search(rf'\b{re.escape(word)}\b', ui):
                logging.debug(f"Context detected: {context} (matched keyword: '{word}')")
                return context

    logging.info(f"No specific context detected for input: {user_input!r}")
    return "general_conversation"


--- session_db.py ---
# app/session_db.py

import os
import redis
from dotenv import load_dotenv

load_dotenv()
redis_url = os.getenv("REDIS_URL", "redis://localhost:6379")

# Initialize Redis client or fallback to in-memory
try:
    _client = redis.from_url(redis_url)
    _client.ping()
    _USE_REDIS = True
except Exception:
    _USE_REDIS = False
    _cache = {
        "context": {},  # for storing context tags like "health_wellness"
        "history": {}   # for storing conversation history
    }
def update_user_context(chat_id: int, context: str):
    key = f"context:{chat_id}"
    if _USE_REDIS:
        _client.set(key, context)
    else:
        _cache["context"][chat_id] = context


def get_user_context(chat_id: int) -> str:
    key = f"context:{chat_id}"
    if _USE_REDIS:
        ctx = _client.get(key)
        return ctx.decode() if ctx else "general_conversation"
    else:
        return _cache["context"].get(chat_id, "general_conversation")


MAX_HISTORY_LEN = 4

def append_user_history(chat_id: int, message: str):
    if _USE_REDIS:
        key = f"history:{chat_id}"
        _client.rpush(key, message)
        _client.ltrim(key, -MAX_HISTORY_LEN, -1)
    else:
        if chat_id not in _cache["history"]:
            _cache["history"][chat_id] = []
        _cache["history"][chat_id].append(message)
        _cache["history"][chat_id] = _cache["history"][chat_id][-MAX_HISTORY_LEN:]

def get_user_history(chat_id: int):
    if _USE_REDIS:
        key = f"history:{chat_id}"
        history = _client.lrange(key, 0, -1)
        return [h.decode() for h in history]
    else:
        return _cache["history"].get(chat_id, [])

--- telegram_bot.py ---
import os
import logging
import tempfile
import asyncio
import datetime
from dotenv import load_dotenv

from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    PollAnswerHandler,
    ContextTypes,
    filters,
)

import speech_recognition as sr
from gtts import gTTS
from pydub import AudioSegment

from app.sea_lion_api import generate_response
from app.langchain_prompts import format_prompt
from app.utils import detect_context
from app.session_db import (
    update_user_context,
    append_user_history,
    get_user_context,
)

# ── ENV / Logging ────────────────────────────────────────────
load_dotenv()
logging.basicConfig(level=logging.INFO)
TOKEN       = os.getenv("TELEGRAM_TOKEN")
WEBHOOK_URL = os.getenv("WEBHOOK_URL")      # e.g. https://happybot-xusj.onrender.com
PORT        = int(os.getenv("PORT", "10000"))

# ── Build the PTB application ─────────────────────────────────
app = ApplicationBuilder().token(TOKEN).build()

# ── Telegram Handlers ─────────────────────────────────────────
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logging.info("[handler] start")
    await update.message.reply_text(
        "🌞 *Welcome to HappyBot!*\n\n"
        "I'm your friendly companion for wellbeing, relaxation, and a little bit of fun. "
        "Type /help to see everything I can do — or just say hello!",
        parse_mode="Markdown"
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logging.info("[handler] help")
    await update.message.reply_text(
        "📘 *Here’s what I can do:*\n\n"
        "👉 `/start` – Begin a fresh conversation with HappyBot\n"
        "❓ `/help` – Show this help menu\n"
        "🗳️ `/checkin` – Schedule a weekly wellbeing check-in\n"
        "🎥 `/exercise` – Watch a short Tai Chi video to relax\n"
        "🌟 `/sticker` – Receive a cheerful sticker reward\n"
        "🎙️ *Send a voice note* – I’ll transcribe and respond in text + voice\n\n"
        "💬 You can also just type messages like:\n"
        "_“I’m feeling down”_ or _“Tell me something uplifting”_\n"
        "and I’ll be here to support you 💖",
        parse_mode="Markdown"
    )
    
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text or ""
    user_id = update.effective_chat.id
    logging.info(f"[handler] message: {user_text!r}")

    # Crisis support
    if any(word in user_text.lower() for word in ["suicidal", "hopeless", "depressed", "end it all"]):
        await update.message.reply_text(
            "💔 I'm truly sorry you're feeling this way. Please know that you're not alone.\n\n"
            "It takes strength to express what you're going through, and I’m here for you 
            " — to listen, support, or simply be present. You matter, and your feelings are valid.\n\n"
            "If things feel overwhelming, I encourage you to talk to someone."
            "You can reach out to Samaritans of Singapore at 📞 1800-221-4444 or visit 🌐 sos.org.sg, "
            "They’re available 24/7 with trained volunteers who care and are ready to listen without judgment.\n\n"
            "In the meantime, if you'd like, I can share a calming exercise or just chat with you — no pressure at all."
            "🤝 You're not alone in this. 🤝",
            parse_mode="Markdown"
        )
        return

    # Empathy support
    if any(word in user_text.lower() for word in ["sad", "lonely", "anxious", "unhappy", "tired"]):
        await update.message.reply_text(
            "🌧️ I hear you. It’s okay to feel this way sometimes. "
            "I’m here to chat, share something uplifting, or just listen. 💙\n\n"
            "Would you like a motivational quote, a breathing exercise, or a fun fact?"
        )
        return

    # Context-based response
    ctx = detect_context(user_text)
    logging.info(f"No specific context detected for input: {user_text!r}") if ctx == "general_conversation" else None
    update_user_context(user_id, ctx)
    append_user_history(user_id, f"User: {user_text}")
    
    try:
        prompt = format_prompt(ctx, user_text, user_id=user_id)
        reply = generate_response(prompt)
    except Exception:
        logging.exception("generate_response failed")
        reply = "😔 Oops! Something went wrong while generating my response. Please try again later."

    append_user_history(user_id, f"Bot: {reply}")
    await update.message.reply_text(f"💬 {reply}")


async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    voice = update.message.voice
    tg_file = await voice.get_file()

    # Step 1: Save .ogg file
    fd, ogg_path = tempfile.mkstemp(suffix=".ogg"); os.close(fd)
    await tg_file.download_to_drive(ogg_path)

    # Step 2: Convert to .wav and normalize
    wav_path = ogg_path.replace(".ogg", ".wav")
    audio = AudioSegment.from_ogg(ogg_path)
    normalized = audio.set_frame_rate(16000).set_channels(1).normalize()
    normalized.export(wav_path, format="wav")
    os.unlink(ogg_path)

    # Step 3: Recognize speech
    recog = sr.Recognizer()
    with sr.AudioFile(wav_path) as src:
        audio_data = recog.record(src)

    try:
        text = recog.recognize_sphinx(audio_data)
    except sr.UnknownValueError:
        text = ""
    except sr.RequestError as e:
        logging.error(f"Sphinx error: {e}")
        text = ""

    os.unlink(wav_path)

    if not text:
        return await update.message.reply_text("😕 I couldn’t understand your voice clearly. Try speaking more slowly or clearly.")

    # Step 4: Generate and reply
    ctx = detect_context(text)
    update_user_context(update.effective_chat.id, ctx)
    prompt = format_prompt(ctx, text)
    reply = generate_response(text, context=ctx, user_id=update.effective_chat.id)

    await update.message.reply_text(reply)
    tts = gTTS(reply)
    with tempfile.NamedTemporaryFile(suffix=".mp3") as mp3_f:
        tts.write_to_fp(mp3_f); mp3_f.flush()
        await update.message.reply_voice(voice=open(mp3_f.name, "rb"))

CHECKIN_Q = "How are you feeling this week?"
CHECKIN_OPTS = ["Great","Okay","Not so good"]

async def checkin_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user_first_name = update.effective_user.first_name or "there"

    try:
        context.job_queue.run_weekly(
            callback=lambda ctx: ctx.bot.send_poll(
                chat_id=chat_id,
                question="🧠 *Weekly Check-In*\n\nHow are you feeling this week?",
                options=["😊 Great", "😐 Okay", "😔 Not so good"],
                is_anonymous=False,
                allows_multiple_answers=False,
                parse_mode="Markdown"
            ),
            time=datetime.time(hour=9, minute=0),  # Every Monday at 9:00 AM (server time)
            days=(0,),  # 0 = Monday
            name=f"checkin_{chat_id}",
            chat_id=chat_id
        )

        await update.message.reply_text(
            f"✅ Got it, {user_first_name}!\n\nI’ve scheduled a gentle weekly check-in "
            f"for every *Monday at 9AM*. You'll get a quick wellness poll in this chat. "
            f"You can always cancel it with /cancelcheckin.",
            parse_mode="Markdown"
        )

    except Exception as e:
        logging.error(f"[checkin_command] Failed to schedule check-in: {e}")
        await update.message.reply_text(
            "⚠️ Sorry, something went wrong while setting up your check-in. Please try again later."
        )

async def handle_poll_answer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.poll_answer.user.id
    first_name = update.poll_answer.user.first_name or "there"
    selected_option = update.poll_answer.option_ids[0] if update.poll_answer.option_ids else None

    if selected_option is not None:
        option_text = ["Great 😊", "Okay 😐", "Not so good 😔"][selected_option]
        logging.info(f"[poll answer] {first_name} selected: {option_text}")

        try:
            await context.bot.send_message(
                chat_id=user_id,
                text=f"💬 Thanks for sharing, {first_name}! You said: *{option_text}*.\n"
                     f"Feel free to check in with me anytime 💛",
                parse_mode="Markdown"
            )
        except Exception as e:
            logging.warning(f"Couldn't send message to user {user_id}: {e}")
    else:
        logging.warning(f"[poll answer] No option selected by user {user_id}")

# ── Register handlers ───────────────────────────────────────────
app.add_handler(CommandHandler("start", start_command))
app.add_handler(CommandHandler("help", help_command))
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
app.add_handler(MessageHandler(filters.VOICE, handle_voice))
app.add_handler(CommandHandler("checkin", checkin_command))
app.add_handler(PollAnswerHandler(handle_poll_answer))

# ── Entrypoint ─────────────────────────────────────────────────
if __name__ == "__main__":
    # app, not application
    app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        url_path="/telegram",
        webhook_url=f"{WEBHOOK_URL}/telegram",
        drop_pending_updates=True,
    )


--- __init__.py ---
# === app/__init__.py ===
"""
App package initializer for the Companion Bot.
"""


--- langchain_prompts.py ---
from langchain.prompts import PromptTemplate
from app.session_db import get_user_history

prompt_templates = {
    "daily_life": PromptTemplate(
        template=(
            "You are a kind, patient assistant for elderly users.\n"
            "Refer to past chats if helpful to keep context.\n\n"
            "Conversation history:\n{history}\n\n"
            "User task:\n{query}\n\n"
            "Response:"
        ),
        input_variables=["history", "query"]
    ),
    "health_wellness": PromptTemplate(
        template=(
            "You are a caring and knowledgeable assistant who helps elderly users understand and manage their health and wellness.\n"
            "Speak in a gentle, reassuring tone using simple, clear language.\n\n"
            "{history}\n"  # Recent context, if available

            "User: {query}\n"
            "Helpful response:"
        ),
        input_variables=["history", "query"]
    ),  
    "emotional_support": PromptTemplate(
        template=(
            "You are a compassionate, gentle companion helping elderly users cope with emotional challenges.\n"
            "Respond with kindness, empathy, and warmth. Speak clearly and use simple, comforting language.\n\n"
            "{history}\n"
            "User: {query}\n"
            "Supportive response:"
        ),
        input_variables=["history", "query"]
    ),
    "technology_help": PromptTemplate(
        template=(
            "You are a calm and patient assistant helping elderly users with technology.\n"
            "Use simple words, guide step-by-step, and reassure users when things are unclear.\n\n"
            "{history}\n"
            "User: {query}\n"
            "Helpful response:"
        ),
        input_variables=["history", "query"]
    ),
    "local_culture": PromptTemplate(
        template=(
            "You are a warm and engaging assistant helping seniors explore their local culture.\n"
            "Share relatable stories, traditions, and events in an uplifting tone.\n\n"
            "{history}\n"
            "User: {query}\n"
            "Culturally relevant response:"
        ),
        input_variables=["history", "query"]
    ),
    "general_conversation": PromptTemplate(
        template=(
            "You are a friendly companion having a light, natural conversation with an elderly user.\n"
            "Keep it cheerful, thoughtful, and easy to follow. Use plain language and stay on familiar topics.\n\n"
            "{history}\n"
            "User: {query}\n"
            "Chatty response:"
        ),
        input_variables=["history", "query"]
    )
}

def format_prompt(context, query, user_id=None):
    prompt_template = prompt_templates.get(context, prompt_templates["general_conversation"])
    history_lines = get_user_history(user_id) if user_id else []
    history_text = "\n".join(history_lines[-4:])  # last 4 lines only

    prompt_with_history = (
        "You are a friendly assistant helping seniors with daily life tasks.\n"
        "Keep responses clear, connected to recent topics, and easy to understand.\n\n"
    )
    if history_text:
        prompt_with_history += f"Conversation so far:\n{history_text}\n\n"

    prompt_with_history += f"User: {query}\nResponse:"
    return prompt_with_history

